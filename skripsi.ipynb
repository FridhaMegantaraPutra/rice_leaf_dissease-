{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:06:24.933384Z",
     "iopub.status.busy": "2024-03-03T17:06:24.933006Z",
     "iopub.status.idle": "2024-03-03T17:06:36.727525Z",
     "shell.execute_reply": "2024-03-03T17:06:36.726298Z",
     "shell.execute_reply.started": "2024-03-03T17:06:24.933354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versi NumPy (melalui CuPy): 13.0.0\n",
      "Versi Matplotlib: 3.7.5\n",
      "Versi OpenCV (cv2): 4.9.0\n",
      "Name: tqdm\n",
      "Version: 4.66.1\n",
      "Summary: Fast, Extensible Progress Meter\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MPL-2.0 AND MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: \n",
      "Required-by: beatrix_jupyterlab, catalyst, cmdstanpy, conda, datasets, dipy, featuretools, fitter, google-generativeai, huggingface-hub, hyperopt, kaggle, kagglehub, lime, mlcrate, mne, momepy, optuna, panel, papermill, prophet, pytorch-lightning, scattertext, segregation, shap, spacy, spopt, tensorflow-datasets, tensorpack, tobler, torchtext, TPOT, transformers, tsfresh, umap-learn, ydata-profiling\n"
     ]
    }
   ],
   "source": [
    "import cupy as np\n",
    "import matplotlib\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "print(\"Versi NumPy (melalui CuPy):\", np.__version__)\n",
    "print(\"Versi Matplotlib:\", matplotlib.__version__)\n",
    "print(\"Versi OpenCV (cv2):\", cv2.__version__)\n",
    "!pip show tqdm\n",
    "\n",
    "\n",
    "# Versi NumPy (melalui CuPy): 13.0.0\n",
    "# Versi Matplotlib: 3.7.5\n",
    "# Versi OpenCV (cv2): 4.9.0\n",
    "# Name: tqdm\n",
    "# Version: 4.66.1\n",
    "# Summary: Fast, Extensible Progress Meter\n",
    "# Home-page: \n",
    "# Author: \n",
    "# Author-email: \n",
    "# License: MPL-2.0 AND MIT\n",
    "# Location: /opt/conda/lib/python3.10/site-packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:06:36.730022Z",
     "iopub.status.busy": "2024-03-03T17:06:36.729697Z",
     "iopub.status.idle": "2024-03-03T17:07:08.125626Z",
     "shell.execute_reply": "2024-03-03T17:07:08.124716Z",
     "shell.execute_reply.started": "2024-03-03T17:06:36.729994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1584/1584 [00:00<00:00, 1373816.69it/s]\n",
      "100%|██████████| 1440/1440 [00:00<00:00, 1939562.54it/s]\n",
      "100%|██████████| 1600/1600 [00:00<00:00, 1289315.35it/s]\n",
      "100%|██████████| 1308/1308 [00:00<00:00, 990458.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5532 400\n"
     ]
    }
   ],
   "source": [
    "import cupy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "\n",
    "np.random.seed(50)\n",
    "\n",
    "CATEGORIES = ['Bacterialblight', 'Blast', 'Brownspot','Tungro']\n",
    "IMG_SIZE = 32\n",
    "\n",
    "def get_data(DATADIR, raw_training_data, raw_testing_data):\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)  # Path ke sub-direktori kategori\n",
    "        class_num = CATEGORIES.index(category)\n",
    "\n",
    "        num_files = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
    "        count = 0\n",
    "\n",
    "        for img in sorted(tqdm(os.listdir(path))):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img))\n",
    "                # Check if image array is not None\n",
    "                if img_array is None:\n",
    "                    print(f\"Failed to read image: {os.path.join(path, img)}\")\n",
    "                    continue\n",
    "\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                count += 1\n",
    "                if count < num_files - 99:\n",
    "                    raw_training_data.append([new_array, class_num])\n",
    "                else:\n",
    "                    raw_testing_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                # Log the exception\n",
    "                print(f\"Error processing image {os.path.join(path, img)}: {e}\")\n",
    "\n",
    "raw_training_data = []\n",
    "raw_testing_data = []\n",
    "\n",
    "DATADIR = \"rice-leaf-disease-image\"\n",
    "\n",
    "get_data(DATADIR, raw_training_data, raw_testing_data)\n",
    "\n",
    "print(len(raw_training_data), len(raw_testing_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:08.127007Z",
     "iopub.status.busy": "2024-03-03T17:07:08.126708Z",
     "iopub.status.idle": "2024-03-03T17:07:10.274002Z",
     "shell.execute_reply": "2024-03-03T17:07:10.273060Z",
     "shell.execute_reply.started": "2024-03-03T17:07:08.126982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5032, 32, 32, 3) (500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from typing import Tuple\n",
    "\n",
    "X_TRAIN = []\n",
    "Y_TRAIN = []\n",
    "\n",
    "X_TEST = []\n",
    "Y_TEST = []\n",
    "\n",
    "X_VAL = []\n",
    "Y_VAL = []\n",
    "\n",
    "\n",
    "for features,label in raw_training_data:\n",
    "    X_TRAIN.append(features)\n",
    "    Y_TRAIN.append(label)\n",
    "\n",
    "\n",
    "for features,label in raw_testing_data:\n",
    "    X_TEST.append(features)\n",
    "    Y_TEST.append(label)\n",
    "\n",
    "X_TRAIN = np.array(X_TRAIN).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "X_TEST = np.array(X_TEST).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "Y_TRAIN = np.array(Y_TRAIN)\n",
    "X_TRAIN, Y_TRAIN = shuffle(X_TRAIN, Y_TRAIN)\n",
    "\n",
    "X_TRAIN = X_TRAIN.astype(float) / 255.\n",
    "X_TEST = X_TEST.astype(float) / 255.\n",
    "\n",
    "\n",
    "X_TRAIN, X_VAL = X_TRAIN[:-500], X_TRAIN[-500:]\n",
    "Y_TRAIN, Y_VAL = Y_TRAIN[:-500], Y_TRAIN[-500:]\n",
    "\n",
    "\"\"\"\n",
    "np.save('xtest.npy',X_TEST)\n",
    "np.save('ytest.npy',Y_TEST)\n",
    "\"\"\"\n",
    "\n",
    "print (X_TRAIN.shape, X_VAL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.277287Z",
     "iopub.status.busy": "2024-03-03T17:07:10.276715Z",
     "iopub.status.idle": "2024-03-03T17:07:10.307284Z",
     "shell.execute_reply": "2024-03-03T17:07:10.306431Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.277259Z"
    }
   },
   "outputs": [],
   "source": [
    "class conv_layer():\n",
    "\n",
    "    def __init__(self, total_filters, filter_shape, lrate = 0.1, padding = 'no_padding', stride = 1, beta1 = 0.9, beta2 = 0.999):\n",
    "        self.filters_ws = np.random.randn(*filter_shape, total_filters) * 0.1\n",
    "        self.filter_bs = np.random.randn(total_filters) * 0.1\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.din_dw = None \n",
    "        self.din_db = None\n",
    "        self.input = None\n",
    "        self.mo = 0\n",
    "        self.acc = 0\n",
    "        self.mo_b = 0\n",
    "        self.acc_b = 0\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, input, training):\n",
    "        #print(self.filters_ws)\n",
    "        self.input = np.array(input, copy=True)\n",
    "\n",
    "\n",
    "        ############### getting output dimentions here ###############\n",
    "        n, input_dim_h, input_dim_w, _ = input.shape\n",
    "        filter_dim_h, filter_dim_w, _, filter_dim_n = self.filters_ws.shape\n",
    "        if self.padding == 'keep_img_dim':\n",
    "            output_shape = n, input_dim_h, input_dim_w, filter_dim_n\n",
    "            filter_dim_h, filter_dim_w, _, _ = self.filters_ws.shape\n",
    "            p_value = (filter_dim_h - 1) // 2, (filter_dim_w - 1) // 2\n",
    "        elif self.padding == 'no_padding':\n",
    "            out_dim_h = (input_dim_h - filter_dim_h) // self.stride + 1\n",
    "            out_dim_w = (input_dim_w - filter_dim_w) // self.stride + 1\n",
    "            output_shape = n, out_dim_h, out_dim_w, filter_dim_n\n",
    "            p_value = 0, 0\n",
    "        ############### got output dimentions ###############\n",
    "\n",
    "        out_dim_n, out_dim_h, out_dim_w, out_dim_c = output_shape\n",
    "\n",
    "        input_padded = self.pad(input, p_value)\n",
    "        output = np.zeros(output_shape)\n",
    "\n",
    "        for i in range(out_dim_h):\n",
    "            for j in range(out_dim_w):\n",
    "                start_pix_x = i * self.stride\n",
    "                end_pix_x = start_pix_x + filter_dim_h\n",
    "                start_pix_y = j * self.stride\n",
    "                end_pix_y = start_pix_y + filter_dim_w\n",
    "\n",
    "                output[:, i, j, :] = np.sum(\n",
    "                    input_padded[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :, np.newaxis] *\n",
    "                    self.filters_ws[np.newaxis, :, :, :],\n",
    "                    axis=(1, 2, 3)\n",
    "                )\n",
    "\n",
    "        #print(output)\n",
    "        return output + self.filter_bs\n",
    "\n",
    "    def backward(self, input , grad):\n",
    "        out_dim_n, out_dim_h, out_dim_w, out_dim_c = grad.shape\n",
    "        n, input_dim_h, input_dim_w, input_dim_c = self.input.shape\n",
    "        filter_dim_h, filter_dim_w, _, _ = self.filters_ws.shape\n",
    "\n",
    "\n",
    "        ############### getting p value here ###############\n",
    "        if self.padding == 'keep_img_dim':\n",
    "            p_value = (filter_dim_h - 1) // 2, (filter_dim_w - 1) // 2\n",
    "        elif self.padding == 'no_padding':\n",
    "            p_value = 0, 0\n",
    "        ############### got p value  ###############\n",
    "\n",
    "\n",
    "\n",
    "        input_padded = self.pad(self.input, p_value)\n",
    "        output = np.zeros_like(input_padded)\n",
    "        #print(grad)\n",
    "        self.din_db = grad.sum(axis=(0, 1, 2)) / n\n",
    "        self.din_dw = np.zeros_like(self.filters_ws)\n",
    "\n",
    "        for i in range(out_dim_h):\n",
    "            for j in range(out_dim_w):\n",
    "                start_pix_x = i * self.stride\n",
    "                end_pix_x = start_pix_x + filter_dim_h\n",
    "                start_pix_y = j * self.stride\n",
    "                end_pix_y = start_pix_y + filter_dim_w\n",
    "                output[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :] += np.sum(\n",
    "                    self.filters_ws[np.newaxis, :, :, :, :] *\n",
    "                    grad[:, i:i+1, j:j+1, np.newaxis, :],\n",
    "                    axis=4\n",
    "                )\n",
    "                self.din_dw += np.sum(\n",
    "                    input_padded[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :, np.newaxis] *\n",
    "                    grad[:, i:i+1, j:j+1, np.newaxis, :],\n",
    "                    axis=0\n",
    "                )\n",
    "\n",
    "        self.din_dw /= n\n",
    "\n",
    "        #print(self.din_dw)\n",
    "\n",
    "        ###################### Adam ###############################\n",
    "        self.mo = self.beta1*self.mo + (1-self.beta1)*(self.din_dw) \n",
    "        self.acc = self.beta2*self.acc + (1-self.beta2)*((self.din_dw) *(self.din_dw))\n",
    "        self.filters_ws += -self.lr * self.mo / (np.sqrt(self.acc) + 1e-7)\n",
    "\n",
    "        self.mo_b = self.beta1*self.mo_b + (1-self.beta1)*(self.din_db) \n",
    "        self.acc_b = self.beta2*self.acc_b + (1-self.beta2)*((self.din_db) *(self.din_db))\n",
    "        self.filter_bs += -self.lr * self.mo_b / (np.sqrt(self.acc_b) + 1e-7)        \n",
    "        ###################### Adam ###############################\n",
    "\n",
    "        return output[:, p_value[0]:p_value[0]+input_dim_h, p_value[1]:p_value[1]+input_dim_w, :]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def pad(array, pad):\n",
    "        return np.pad(\n",
    "            array=array,\n",
    "            pad_width=((0, 0), (pad[0], pad[0]), (pad[1], pad[1]), (0, 0)),\n",
    "            mode='constant'\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.309305Z",
     "iopub.status.busy": "2024-03-03T17:07:10.308703Z",
     "iopub.status.idle": "2024-03-03T17:07:10.326967Z",
     "shell.execute_reply": "2024-03-03T17:07:10.325928Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.309270Z"
    }
   },
   "outputs": [],
   "source": [
    "class pool_layer():\n",
    "\n",
    "    def __init__(self, input_dim, stride = 2):\n",
    "        self.pool_dim = input_dim\n",
    "        self.stride = stride\n",
    "        self.input = None\n",
    "        self.max_pixels = {}\n",
    "\n",
    "    def forward(self, input, training):\n",
    "        #print(input.shape)\n",
    "        self.input = np.array(input, copy=True)\n",
    "        n, input_dim_h, input_dim_w, c = input.shape\n",
    "        pool_x_dim, pool_y_dim = self.pool_dim\n",
    "        out_dim_h = 1 + (input_dim_h - pool_x_dim) // self.stride\n",
    "        out_dim_w = 1 + (input_dim_w - pool_y_dim) // self.stride\n",
    "        output = np.zeros((n, out_dim_h, out_dim_w, c))\n",
    "\n",
    "        for i in range(out_dim_h):\n",
    "            for j in range(out_dim_w):\n",
    "                start_pix_x = i * self.stride\n",
    "                end_pix_x = start_pix_x + pool_x_dim\n",
    "                start_pix_y = j * self.stride\n",
    "                end_pix_y = start_pix_y + pool_y_dim\n",
    "                focus_area = input[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :]\n",
    "                self.store_max_pixels(focus_area, (i, j))\n",
    "                output[:, i, j, :] = np.max(focus_area, axis=(1, 2))\n",
    "\n",
    "        #print(output)\n",
    "        return output\n",
    "\n",
    "    def backward(self, input,grad):\n",
    "        #print(grad)\n",
    "        output = np.zeros_like(self.input)\n",
    "        n, out_dim_h, out_dim_w, c = grad.shape\n",
    "        pool_x_dim, pool_y_dim = self.pool_dim\n",
    "        for i in range(out_dim_h):\n",
    "            for j in range(out_dim_w):\n",
    "                start_pix_x = i * self.stride\n",
    "                end_pix_x = start_pix_x + pool_x_dim\n",
    "                start_pix_y = j * self.stride\n",
    "                end_pix_y = start_pix_y + pool_y_dim\n",
    "                output[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :] += grad[:, i:i + 1, j:j + 1, :] * self.max_pixels[(i, j)]\n",
    "        #print(output)\n",
    "        return output\n",
    "\n",
    "    def store_max_pixels(self, area_pixels, i_j_location):\n",
    "        mark_max = np.zeros_like(area_pixels)\n",
    "        n, h, w, c = area_pixels.shape\n",
    "        area_pixels = area_pixels.reshape(n, h * w, c)\n",
    "        max_locations = np.argmax(area_pixels, axis=1)\n",
    "        n_idx, c_idx = np.indices((n, c))\n",
    "        mark_max.reshape(n, h * w, c)[n_idx, max_locations, c_idx] = 1\n",
    "        self.max_pixels[i_j_location] = mark_max\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.329165Z",
     "iopub.status.busy": "2024-03-03T17:07:10.328570Z",
     "iopub.status.idle": "2024-03-03T17:07:10.339732Z",
     "shell.execute_reply": "2024-03-03T17:07:10.338688Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.329128Z"
    }
   },
   "outputs": [],
   "source": [
    "class reshape_layer():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input_shape = ()\n",
    "\n",
    "    def forward(self, input, training):\n",
    "        self.input_shape = input.shape\n",
    "        return np.ravel(input).reshape(input.shape[0], -1)\n",
    "\n",
    "    def backward(self,input , grad):\n",
    "        return grad.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.341425Z",
     "iopub.status.busy": "2024-03-03T17:07:10.341091Z",
     "iopub.status.idle": "2024-03-03T17:07:10.356406Z",
     "shell.execute_reply": "2024-03-03T17:07:10.355481Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.341402Z"
    }
   },
   "outputs": [],
   "source": [
    "all_ws = []\n",
    "class weights_layer():\n",
    "    def __init__(self, fan_in, fan_out, lr=0.05, beta1 = 0.9, beta2 = 0.999 , lamdaa = 0.0001):\n",
    "        self.lamdaa = lamdaa\n",
    "        self.lr = lr\n",
    "        self.ws = np.random.randn(fan_in, fan_out)/np.sqrt(fan_in)\n",
    "        self.bs = np.zeros(fan_out)\n",
    "        self.mo = 0\n",
    "        self.acc = 0\n",
    "        self.mo_b = 0\n",
    "        self.acc_b = 0\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        \n",
    "    def forward(self,input, training):\n",
    "        #all_ws.append(self.ws)\n",
    "        #print(input.shape)\n",
    "        #print(np.dot(input,self.ws) + self.bs)\n",
    "        return np.dot(input,self.ws) + self.bs\n",
    "    \n",
    "    def backward(self,input,grad_output):\n",
    "        dout_din = np.dot(grad_output, self.ws.T)\n",
    "        dout_dws = np.dot(input.T, grad_output)\n",
    "        dout_dbs = grad_output.mean(axis=0)*input.shape[0]\n",
    "        \n",
    "        assert dout_dws.shape == self.ws.shape and dout_dbs.shape == self.bs.shape\n",
    "        #print(dout_dws)\n",
    "        ###################### Adam ###############################\n",
    "        self.mo = self.beta1*self.mo + (1-self.beta1)*(dout_dws) \n",
    "        self.acc = self.beta2*self.acc + (1-self.beta2)*((dout_dws) *(dout_dws))\n",
    "        self.ws += -self.lr * self.mo / (np.sqrt(self.acc) + 1e-7)\n",
    "\n",
    "        self.mo_b = self.beta1*self.mo_b + (1-self.beta1)*(dout_dbs) \n",
    "        self.acc_b = self.beta2*self.acc_b + (1-self.beta2)*((dout_dbs) *(dout_dbs))\n",
    "        self.bs += -self.lr * self.mo_b / (np.sqrt(self.acc_b) + 1e-7) \n",
    "        ###################### Adam ###############################\n",
    "        \"\"\"\n",
    "        self.ws = self.ws - self.lr * dout_dws  #+ (self.lamdaa * np.sum(self.ws))/input.shape[0]\n",
    "        self.bs = self.bs - self.lr * dout_dbs  #+ (self.lamdaa * np.sum(self.bs))/input.shape[0]  \n",
    "        \"\"\"\n",
    "        #print(dout_din)\n",
    "        return dout_din"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.358222Z",
     "iopub.status.busy": "2024-03-03T17:07:10.357623Z",
     "iopub.status.idle": "2024-03-03T17:07:10.369050Z",
     "shell.execute_reply": "2024-03-03T17:07:10.368150Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.358191Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input, training):\n",
    "        relu_forward = np.maximum(0,input)\n",
    "        return relu_forward\n",
    "    \n",
    "    def backward(self, input, grad_output):\n",
    "        relu_grad = input > 0\n",
    "        return grad_output*relu_grad\n",
    "\n",
    "class tanh():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input, training):\n",
    "        return np.tanh(input)\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "      return grad_output*(1-np.tanh(input)**2)\n",
    "\n",
    "class sigmoid():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input, training):\n",
    "        return 1/(1+np.exp(-1* input))\n",
    "    def backward(self, input, grad_output):\n",
    "        return grad_output * (input*(1-input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.370397Z",
     "iopub.status.busy": "2024-03-03T17:07:10.370147Z",
     "iopub.status.idle": "2024-03-03T17:07:10.382619Z",
     "shell.execute_reply": "2024-03-03T17:07:10.381778Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.370376Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input, training):\n",
    "        relu_forward = np.maximum(0,input)\n",
    "        return relu_forward\n",
    "    \n",
    "    def backward(self, input, grad_output):\n",
    "        relu_grad = input > 0\n",
    "        return grad_output*relu_grad\n",
    "\n",
    "class tanh():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input, training):\n",
    "        return np.tanh(input)\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "      return grad_output*(1-np.tanh(input)**2)\n",
    "\n",
    "class sigmoid():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input, training):\n",
    "        return 1/(1+np.exp(-1* input))\n",
    "    def backward(self, input, grad_output):\n",
    "        return grad_output * (input*(1-input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.386446Z",
     "iopub.status.busy": "2024-03-03T17:07:10.385858Z",
     "iopub.status.idle": "2024-03-03T17:07:10.393704Z",
     "shell.execute_reply": "2024-03-03T17:07:10.392832Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.386414Z"
    }
   },
   "outputs": [],
   "source": [
    "def NLL(expected_probabilities,actual_labels, m, lamdaa = 0.0001):\n",
    "\n",
    "\n",
    "    correct_prob = expected_probabilities[np.arange(len(expected_probabilities)),actual_labels]\n",
    "\n",
    "    p = np.exp(correct_prob) / np.sum(np.exp(expected_probabilities),axis=-1)\n",
    "\n",
    "    loss = -1 * np.log(p)\n",
    "    \n",
    "    \"\"\"\n",
    "    s_reg = 0\n",
    "    for i in all_ws:\n",
    "      s_reg += np.sum(np.square(i))\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    #print(expected_probabilities)\n",
    "    return loss #+ (lamdaa * s_reg)/m\n",
    "\n",
    "def back_NLL(expected_probabilities,actual_labels):\n",
    "\n",
    "    hotmap = np.zeros_like(expected_probabilities)\n",
    "    hotmap[np.arange(len(expected_probabilities)),actual_labels] = 1\n",
    "    \n",
    "    ratios = np.exp(expected_probabilities) / np.exp(expected_probabilities).sum(axis=-1,keepdims=True)\n",
    "    \n",
    "    \n",
    "    #print((- hotmap + ratios) / expected_probabilities.shape[0]) \n",
    "    return (- hotmap + ratios) / expected_probabilities.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.395048Z",
     "iopub.status.busy": "2024-03-03T17:07:10.394756Z",
     "iopub.status.idle": "2024-03-03T17:07:10.406749Z",
     "shell.execute_reply": "2024-03-03T17:07:10.405934Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.395027Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_batch(CNN, X, training):\n",
    "    all_layers_outputs = []\n",
    "    received = X\n",
    "    for layer in CNN:\n",
    "        all_layers_outputs.append(layer.forward(received, training))\n",
    "        received = all_layers_outputs[-1]\n",
    "  \n",
    "    all_ws=[]\n",
    "    assert len(all_layers_outputs) == len(CNN)\n",
    "    \n",
    "    return all_layers_outputs\n",
    "\n",
    "def predict(CNN,X, Y, training):\n",
    "    expected_probabilities = run_batch(CNN,X, training)[-1]\n",
    "    losses = NLL(expected_probabilities,Y, X.shape[0])\n",
    "    return (expected_probabilities.argmax(axis=-1) , np.mean(losses))\n",
    "\n",
    "def train(CNN,X,acutal_labels, training):\n",
    "\n",
    "    layers_outputs = run_batch(CNN,X, training)\n",
    "    layers_inputs = [X]+layers_outputs \n",
    "    expected_probs = layers_outputs[-1]\n",
    "    loss = NLL(expected_probs,acutal_labels, X.shape[0])\n",
    "    loss_grad = back_NLL(expected_probs,acutal_labels)\n",
    "\n",
    "    for layer_index in range(len(CNN))[::-1]:\n",
    "        layer = CNN[layer_index]\n",
    "        loss_grad = layer.backward(layers_inputs[layer_index],loss_grad)\n",
    "        \n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.408078Z",
     "iopub.status.busy": "2024-03-03T17:07:10.407777Z",
     "iopub.status.idle": "2024-03-03T17:07:10.416928Z",
     "shell.execute_reply": "2024-03-03T17:07:10.416017Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.408056Z"
    }
   },
   "outputs": [],
   "source": [
    "class dropout_layer():\n",
    "\n",
    "    def __init__(self, keep_prob):\n",
    "        self.cutoff_prob = keep_prob\n",
    "        self.zeros_for_dropped = None\n",
    "\n",
    "    def forward(self, input, training):\n",
    "        if training:\n",
    "            self.zeros_for_dropped = (np.random.rand(*input.shape) < self.cutoff_prob)\n",
    "            return self.drop(input, self.zeros_for_dropped)\n",
    "        else:\n",
    "            return input\n",
    "\n",
    "    def backward(self, input, grad):\n",
    "        return self.drop(grad, self.zeros_for_dropped)\n",
    "\n",
    "    def drop(self, input, zeros_for_dropped):\n",
    "        input *= zeros_for_dropped\n",
    "        input /= self.cutoff_prob\n",
    "        #print(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.418246Z",
     "iopub.status.busy": "2024-03-03T17:07:10.417921Z",
     "iopub.status.idle": "2024-03-03T17:07:10.429205Z",
     "shell.execute_reply": "2024-03-03T17:07:10.428357Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.418216Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.430642Z",
     "iopub.status.busy": "2024-03-03T17:07:10.430317Z",
     "iopub.status.idle": "2024-03-03T17:07:10.438675Z",
     "shell.execute_reply": "2024-03-03T17:07:10.437928Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.430601Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_count = 20\n",
    "# learning_rates = []\n",
    "# train_log = []\n",
    "# val_log = []\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "# n_epochs = 3\n",
    "\n",
    "# for count in range(max_count):\n",
    "\n",
    "#   lr = 10**np.random.uniform(-0.5,-4)\n",
    "\n",
    "#   CNN = []\n",
    "\n",
    "#   CNN.append(conv_layer(8, (3,3,3), lr))\n",
    "#   CNN.append(ReLU())\n",
    "#   CNN.append(pool_layer((2,2)))\n",
    "\n",
    "#   CNN.append(conv_layer(16, (3,3,8) , lr))\n",
    "#   CNN.append(ReLU())\n",
    "#   CNN.append(pool_layer((2,2)))\n",
    "\n",
    "\n",
    "#   CNN.append(conv_layer(32, (3,3,16), lr))\n",
    "#   CNN.append(ReLU())\n",
    "#   CNN.append(pool_layer((2,2)))\n",
    "\n",
    "\n",
    "#   CNN.append(reshape_layer())\n",
    "\n",
    "\n",
    "#   CNN.append(weights_layer(128,100,lr))\n",
    "#   CNN.append(ReLU())\n",
    "#   CNN.append(dropout_layer(0.6))\n",
    "#   CNN.append(weights_layer(100,100,lr))\n",
    "#   CNN.append(ReLU())\n",
    "#   CNN.append(dropout_layer(0.6))\n",
    "#   CNN.append(weights_layer(100,5,lr))\n",
    "\n",
    "#   for epoch in range(n_epochs):\n",
    "\n",
    "#     train(CNN,X_TRAIN,Y_TRAIN, 1)\n",
    "\n",
    "#     train_predictions, train_loss = predict(CNN,X_TRAIN, Y_TRAIN, 0)\n",
    "\n",
    "#     val_predictions, val_loss = predict(CNN,X_VAL, Y_VAL, 0)\n",
    "\n",
    "#     train_log.append(np.mean(train_predictions==Y_TRAIN))\n",
    "\n",
    "#     val_log.append(np.mean(val_predictions==Y_VAL))\n",
    "\n",
    "#     train_losses.append(train_loss)\n",
    "\n",
    "#     val_losses.append(val_loss)\n",
    "\n",
    "#     learning_rates.append(lr)\n",
    "\n",
    "#     print(\"Trial %d epoch %d got t_acc = %f, v_acc = %f, t_loss = %f, and v_loss = %f at lr = %f\" % (count, epoch, train_log[-1], train_losses[-1],val_losses[-1], val_log[-1], lr))\n",
    "\n",
    "# print()\n",
    "# print(\"Got highest train accuracy = %f at lr = %f\" % (max(train_log), learning_rates[train_log.index(max(train_log))]))\n",
    "# print(\"Got highest val accuracy = %f at lr = %f\" % (max(val_log), learning_rates[val_log.index(max(val_log))]))\n",
    "# print(\"Got lowest train loss = %f at lr = %f\" % (min(train_losses), learning_rates[train_losses.index(min(train_losses))]))\n",
    "# print(\"Got lowest val loss = %f at lr = %f\" % (min(val_losses), learning_rates[val_losses.index(min(val_losses))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:07:10.439776Z",
     "iopub.status.busy": "2024-03-03T17:07:10.439548Z",
     "iopub.status.idle": "2024-03-03T17:24:31.831161Z",
     "shell.execute_reply": "2024-03-03T17:24:31.830191Z",
     "shell.execute_reply.started": "2024-03-03T17:07:10.439757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran epoch 0 and got t_acc = 0.259141 val_acc = 0.304000, t_loss = 1.590091, v_loss = 1.588718\n",
      "Ran epoch 1 and got t_acc = 0.281598 val_acc = 0.276000, t_loss = 1.549434, v_loss = 1.549227\n",
      "Ran epoch 2 and got t_acc = 0.297099 val_acc = 0.296000, t_loss = 1.508914, v_loss = 1.509761\n",
      "Ran epoch 3 and got t_acc = 0.413951 val_acc = 0.410000, t_loss = 1.463443, v_loss = 1.466126\n",
      "Ran epoch 4 and got t_acc = 0.299086 val_acc = 0.266000, t_loss = 1.423076, v_loss = 1.429361\n",
      "Ran epoch 5 and got t_acc = 0.270270 val_acc = 0.248000, t_loss = 1.396303, v_loss = 1.406475\n",
      "Ran epoch 6 and got t_acc = 0.270270 val_acc = 0.248000, t_loss = 1.384611, v_loss = 1.395982\n",
      "Ran epoch 7 and got t_acc = 0.270270 val_acc = 0.248000, t_loss = 1.379468, v_loss = 1.387623\n",
      "Ran epoch 8 and got t_acc = 0.270270 val_acc = 0.248000, t_loss = 1.378342, v_loss = 1.382060\n",
      "Ran epoch 9 and got t_acc = 0.273052 val_acc = 0.248000, t_loss = 1.380376, v_loss = 1.381370\n",
      "Ran epoch 10 and got t_acc = 0.463037 val_acc = 0.438000, t_loss = 1.380852, v_loss = 1.381641\n",
      "Ran epoch 11 and got t_acc = 0.471781 val_acc = 0.446000, t_loss = 1.379081, v_loss = 1.381402\n",
      "Ran epoch 12 and got t_acc = 0.445946 val_acc = 0.414000, t_loss = 1.374874, v_loss = 1.379529\n",
      "Ran epoch 13 and got t_acc = 0.344595 val_acc = 0.294000, t_loss = 1.367202, v_loss = 1.374881\n",
      "Ran epoch 14 and got t_acc = 0.273052 val_acc = 0.248000, t_loss = 1.356508, v_loss = 1.367823\n",
      "Ran epoch 15 and got t_acc = 0.270270 val_acc = 0.248000, t_loss = 1.347517, v_loss = 1.362869\n",
      "Ran epoch 16 and got t_acc = 0.279213 val_acc = 0.252000, t_loss = 1.337318, v_loss = 1.354127\n",
      "Ran epoch 17 and got t_acc = 0.410175 val_acc = 0.358000, t_loss = 1.323833, v_loss = 1.339412\n",
      "Ran epoch 18 and got t_acc = 0.476153 val_acc = 0.452000, t_loss = 1.311885, v_loss = 1.325424\n",
      "Ran epoch 19 and got t_acc = 0.484897 val_acc = 0.456000, t_loss = 1.295492, v_loss = 1.307924\n",
      "Ran epoch 20 and got t_acc = 0.484698 val_acc = 0.460000, t_loss = 1.270596, v_loss = 1.282766\n",
      "Ran epoch 21 and got t_acc = 0.467806 val_acc = 0.446000, t_loss = 1.242519, v_loss = 1.256501\n",
      "Ran epoch 22 and got t_acc = 0.482909 val_acc = 0.460000, t_loss = 1.210585, v_loss = 1.225761\n",
      "Ran epoch 23 and got t_acc = 0.486685 val_acc = 0.466000, t_loss = 1.180034, v_loss = 1.193742\n",
      "Ran epoch 24 and got t_acc = 0.496423 val_acc = 0.476000, t_loss = 1.146644, v_loss = 1.162476\n",
      "Ran epoch 25 and got t_acc = 0.508347 val_acc = 0.484000, t_loss = 1.110510, v_loss = 1.127036\n",
      "Ran epoch 26 and got t_acc = 0.512719 val_acc = 0.494000, t_loss = 1.072656, v_loss = 1.091087\n",
      "Ran epoch 27 and got t_acc = 0.515103 val_acc = 0.500000, t_loss = 1.035814, v_loss = 1.056301\n",
      "Ran epoch 28 and got t_acc = 0.569555 val_acc = 0.568000, t_loss = 1.007286, v_loss = 1.023770\n",
      "Ran epoch 29 and got t_acc = 0.508943 val_acc = 0.474000, t_loss = 1.037476, v_loss = 1.081019\n",
      "Ran epoch 30 and got t_acc = 0.601749 val_acc = 0.594000, t_loss = 1.001143, v_loss = 1.010306\n",
      "Ran epoch 31 and got t_acc = 0.638911 val_acc = 0.632000, t_loss = 0.958311, v_loss = 0.977530\n",
      "Ran epoch 32 and got t_acc = 0.599364 val_acc = 0.588000, t_loss = 0.965592, v_loss = 1.009638\n",
      "Ran epoch 33 and got t_acc = 0.624801 val_acc = 0.618000, t_loss = 0.937451, v_loss = 0.980760\n",
      "Ran epoch 34 and got t_acc = 0.640501 val_acc = 0.622000, t_loss = 0.934013, v_loss = 0.959389\n",
      "Ran epoch 35 and got t_acc = 0.649444 val_acc = 0.646000, t_loss = 0.916024, v_loss = 0.945889\n",
      "Ran epoch 36 and got t_acc = 0.626590 val_acc = 0.612000, t_loss = 0.906867, v_loss = 0.956051\n",
      "Ran epoch 37 and got t_acc = 0.627583 val_acc = 0.608000, t_loss = 0.902244, v_loss = 0.950839\n",
      "Ran epoch 38 and got t_acc = 0.676272 val_acc = 0.664000, t_loss = 0.884525, v_loss = 0.915611\n",
      "Ran epoch 39 and got t_acc = 0.680246 val_acc = 0.670000, t_loss = 0.885632, v_loss = 0.911318\n",
      "Ran epoch 40 and got t_acc = 0.683824 val_acc = 0.678000, t_loss = 0.858553, v_loss = 0.896508\n",
      "Ran epoch 41 and got t_acc = 0.667329 val_acc = 0.666000, t_loss = 0.857622, v_loss = 0.906743\n",
      "Ran epoch 42 and got t_acc = 0.689984 val_acc = 0.676000, t_loss = 0.838685, v_loss = 0.877950\n",
      "Ran epoch 43 and got t_acc = 0.694754 val_acc = 0.696000, t_loss = 0.836299, v_loss = 0.862966\n",
      "Ran epoch 44 and got t_acc = 0.699324 val_acc = 0.694000, t_loss = 0.820416, v_loss = 0.851695\n",
      "Ran epoch 45 and got t_acc = 0.700914 val_acc = 0.696000, t_loss = 0.804713, v_loss = 0.851095\n",
      "Ran epoch 46 and got t_acc = 0.699523 val_acc = 0.698000, t_loss = 0.796088, v_loss = 0.845206\n",
      "Ran epoch 47 and got t_acc = 0.707075 val_acc = 0.698000, t_loss = 0.783780, v_loss = 0.822028\n",
      "Ran epoch 48 and got t_acc = 0.713434 val_acc = 0.710000, t_loss = 0.776207, v_loss = 0.809675\n",
      "Ran epoch 49 and got t_acc = 0.716812 val_acc = 0.702000, t_loss = 0.759072, v_loss = 0.806703\n",
      "Ran epoch 50 and got t_acc = 0.712639 val_acc = 0.698000, t_loss = 0.749578, v_loss = 0.804287\n",
      "Ran epoch 51 and got t_acc = 0.712242 val_acc = 0.708000, t_loss = 0.740163, v_loss = 0.780619\n",
      "Ran epoch 52 and got t_acc = 0.723172 val_acc = 0.708000, t_loss = 0.727631, v_loss = 0.768068\n",
      "Ran epoch 53 and got t_acc = 0.726351 val_acc = 0.702000, t_loss = 0.717983, v_loss = 0.770133\n",
      "Ran epoch 54 and got t_acc = 0.723370 val_acc = 0.708000, t_loss = 0.705422, v_loss = 0.753900\n",
      "Ran epoch 55 and got t_acc = 0.723370 val_acc = 0.712000, t_loss = 0.697108, v_loss = 0.742622\n",
      "Ran epoch 56 and got t_acc = 0.729531 val_acc = 0.706000, t_loss = 0.685523, v_loss = 0.741277\n",
      "Ran epoch 57 and got t_acc = 0.733903 val_acc = 0.704000, t_loss = 0.676840, v_loss = 0.732230\n",
      "Ran epoch 58 and got t_acc = 0.720588 val_acc = 0.706000, t_loss = 0.673381, v_loss = 0.712413\n",
      "Ran epoch 59 and got t_acc = 0.733108 val_acc = 0.698000, t_loss = 0.660303, v_loss = 0.725958\n",
      "Ran epoch 60 and got t_acc = 0.731320 val_acc = 0.702000, t_loss = 0.647241, v_loss = 0.704441\n",
      "Ran epoch 61 and got t_acc = 0.729134 val_acc = 0.712000, t_loss = 0.644142, v_loss = 0.684264\n",
      "Ran epoch 62 and got t_acc = 0.744237 val_acc = 0.712000, t_loss = 0.652059, v_loss = 0.714204\n",
      "Ran epoch 63 and got t_acc = 0.717011 val_acc = 0.716000, t_loss = 0.653837, v_loss = 0.695538\n",
      "Ran epoch 64 and got t_acc = 0.735890 val_acc = 0.708000, t_loss = 0.623578, v_loss = 0.689791\n",
      "Ran epoch 65 and got t_acc = 0.750199 val_acc = 0.728000, t_loss = 0.632648, v_loss = 0.690285\n",
      "Ran epoch 66 and got t_acc = 0.728935 val_acc = 0.726000, t_loss = 0.638113, v_loss = 0.670915\n",
      "Ran epoch 67 and got t_acc = 0.744436 val_acc = 0.718000, t_loss = 0.608598, v_loss = 0.670228\n",
      "Ran epoch 68 and got t_acc = 0.742051 val_acc = 0.704000, t_loss = 0.620962, v_loss = 0.697727\n",
      "Ran epoch 69 and got t_acc = 0.730326 val_acc = 0.720000, t_loss = 0.611603, v_loss = 0.660619\n",
      "Ran epoch 70 and got t_acc = 0.749205 val_acc = 0.736000, t_loss = 0.596814, v_loss = 0.636017\n",
      "Ran epoch 71 and got t_acc = 0.744833 val_acc = 0.718000, t_loss = 0.609090, v_loss = 0.661672\n",
      "Ran epoch 72 and got t_acc = 0.743641 val_acc = 0.720000, t_loss = 0.590989, v_loss = 0.647650\n",
      "Ran epoch 73 and got t_acc = 0.743243 val_acc = 0.720000, t_loss = 0.589242, v_loss = 0.644477\n",
      "Ran epoch 74 and got t_acc = 0.756955 val_acc = 0.726000, t_loss = 0.595871, v_loss = 0.654786\n",
      "Ran epoch 75 and got t_acc = 0.757353 val_acc = 0.736000, t_loss = 0.575505, v_loss = 0.617891\n",
      "Ran epoch 76 and got t_acc = 0.746622 val_acc = 0.738000, t_loss = 0.586286, v_loss = 0.625718\n",
      "Ran epoch 77 and got t_acc = 0.751987 val_acc = 0.724000, t_loss = 0.582294, v_loss = 0.647043\n",
      "Ran epoch 78 and got t_acc = 0.759738 val_acc = 0.732000, t_loss = 0.565332, v_loss = 0.626338\n",
      "Ran epoch 79 and got t_acc = 0.752981 val_acc = 0.736000, t_loss = 0.571173, v_loss = 0.617690\n",
      "Ran epoch 80 and got t_acc = 0.762122 val_acc = 0.734000, t_loss = 0.563198, v_loss = 0.611374\n",
      "Ran epoch 81 and got t_acc = 0.764110 val_acc = 0.740000, t_loss = 0.557522, v_loss = 0.610999\n",
      "Ran epoch 82 and got t_acc = 0.755366 val_acc = 0.732000, t_loss = 0.560889, v_loss = 0.614871\n",
      "Ran epoch 83 and got t_acc = 0.764308 val_acc = 0.736000, t_loss = 0.549965, v_loss = 0.611220\n",
      "Ran epoch 84 and got t_acc = 0.766693 val_acc = 0.740000, t_loss = 0.550963, v_loss = 0.608199\n",
      "Ran epoch 85 and got t_acc = 0.761328 val_acc = 0.744000, t_loss = 0.549260, v_loss = 0.594492\n",
      "Ran epoch 86 and got t_acc = 0.770866 val_acc = 0.742000, t_loss = 0.540503, v_loss = 0.595256\n",
      "Ran epoch 87 and got t_acc = 0.771065 val_acc = 0.744000, t_loss = 0.538607, v_loss = 0.597665\n",
      "Ran epoch 88 and got t_acc = 0.764308 val_acc = 0.748000, t_loss = 0.538614, v_loss = 0.589155\n",
      "Ran epoch 89 and got t_acc = 0.776033 val_acc = 0.750000, t_loss = 0.533926, v_loss = 0.588391\n",
      "Ran epoch 90 and got t_acc = 0.776630 val_acc = 0.750000, t_loss = 0.527733, v_loss = 0.576479\n",
      "Ran epoch 91 and got t_acc = 0.771065 val_acc = 0.752000, t_loss = 0.527974, v_loss = 0.576896\n",
      "Ran epoch 92 and got t_acc = 0.775437 val_acc = 0.752000, t_loss = 0.531227, v_loss = 0.591918\n",
      "Ran epoch 93 and got t_acc = 0.770668 val_acc = 0.750000, t_loss = 0.525020, v_loss = 0.572774\n",
      "Ran epoch 94 and got t_acc = 0.782591 val_acc = 0.762000, t_loss = 0.516987, v_loss = 0.563480\n",
      "Ran epoch 95 and got t_acc = 0.782989 val_acc = 0.762000, t_loss = 0.521763, v_loss = 0.573161\n",
      "Ran epoch 96 and got t_acc = 0.770072 val_acc = 0.744000, t_loss = 0.519681, v_loss = 0.566690\n",
      "Ran epoch 97 and got t_acc = 0.786765 val_acc = 0.752000, t_loss = 0.510248, v_loss = 0.565348\n",
      "Ran epoch 98 and got t_acc = 0.787560 val_acc = 0.764000, t_loss = 0.509593, v_loss = 0.563451\n",
      "Ran epoch 99 and got t_acc = 0.776630 val_acc = 0.752000, t_loss = 0.513433, v_loss = 0.557306\n",
      "Ran epoch 100 and got t_acc = 0.790541 val_acc = 0.764000, t_loss = 0.509658, v_loss = 0.568425\n",
      "Ran epoch 101 and got t_acc = 0.786963 val_acc = 0.762000, t_loss = 0.501263, v_loss = 0.555519\n",
      "Ran epoch 102 and got t_acc = 0.790143 val_acc = 0.762000, t_loss = 0.498928, v_loss = 0.544703\n",
      "Ran epoch 103 and got t_acc = 0.789944 val_acc = 0.764000, t_loss = 0.503848, v_loss = 0.551620\n",
      "Ran epoch 104 and got t_acc = 0.778021 val_acc = 0.752000, t_loss = 0.502840, v_loss = 0.548346\n",
      "Ran epoch 105 and got t_acc = 0.799086 val_acc = 0.764000, t_loss = 0.495646, v_loss = 0.556815\n",
      "Ran epoch 106 and got t_acc = 0.799285 val_acc = 0.770000, t_loss = 0.488745, v_loss = 0.541183\n",
      "Ran epoch 107 and got t_acc = 0.785970 val_acc = 0.762000, t_loss = 0.494729, v_loss = 0.533201\n",
      "Ran epoch 108 and got t_acc = 0.799682 val_acc = 0.776000, t_loss = 0.495784, v_loss = 0.548804\n",
      "Ran epoch 109 and got t_acc = 0.787560 val_acc = 0.758000, t_loss = 0.487334, v_loss = 0.538024\n",
      "Ran epoch 110 and got t_acc = 0.800477 val_acc = 0.772000, t_loss = 0.481431, v_loss = 0.537697\n",
      "Ran epoch 111 and got t_acc = 0.801669 val_acc = 0.770000, t_loss = 0.480887, v_loss = 0.530473\n",
      "Ran epoch 112 and got t_acc = 0.796900 val_acc = 0.774000, t_loss = 0.482957, v_loss = 0.520394\n",
      "Ran epoch 113 and got t_acc = 0.804650 val_acc = 0.776000, t_loss = 0.475188, v_loss = 0.522232\n",
      "Ran epoch 114 and got t_acc = 0.806638 val_acc = 0.768000, t_loss = 0.473263, v_loss = 0.528822\n",
      "Ran epoch 115 and got t_acc = 0.794515 val_acc = 0.774000, t_loss = 0.474334, v_loss = 0.523830\n",
      "Ran epoch 116 and got t_acc = 0.806041 val_acc = 0.790000, t_loss = 0.473457, v_loss = 0.523901\n",
      "Ran epoch 117 and got t_acc = 0.797893 val_acc = 0.772000, t_loss = 0.471597, v_loss = 0.512677\n",
      "Ran epoch 118 and got t_acc = 0.808227 val_acc = 0.788000, t_loss = 0.463848, v_loss = 0.513142\n",
      "Ran epoch 119 and got t_acc = 0.810413 val_acc = 0.782000, t_loss = 0.462672, v_loss = 0.518979\n",
      "Ran epoch 120 and got t_acc = 0.801272 val_acc = 0.776000, t_loss = 0.464652, v_loss = 0.512998\n",
      "Ran epoch 121 and got t_acc = 0.808426 val_acc = 0.790000, t_loss = 0.461519, v_loss = 0.512212\n",
      "Ran epoch 122 and got t_acc = 0.806439 val_acc = 0.782000, t_loss = 0.456102, v_loss = 0.502772\n",
      "Ran epoch 123 and got t_acc = 0.808625 val_acc = 0.776000, t_loss = 0.454935, v_loss = 0.505971\n",
      "Ran epoch 124 and got t_acc = 0.811407 val_acc = 0.788000, t_loss = 0.456027, v_loss = 0.509215\n",
      "Ran epoch 125 and got t_acc = 0.805445 val_acc = 0.784000, t_loss = 0.455127, v_loss = 0.496595\n",
      "Ran epoch 126 and got t_acc = 0.811010 val_acc = 0.790000, t_loss = 0.448852, v_loss = 0.497125\n",
      "Ran epoch 127 and got t_acc = 0.812798 val_acc = 0.782000, t_loss = 0.446323, v_loss = 0.496738\n",
      "Ran epoch 128 and got t_acc = 0.809618 val_acc = 0.784000, t_loss = 0.446052, v_loss = 0.494964\n",
      "Ran epoch 129 and got t_acc = 0.812401 val_acc = 0.782000, t_loss = 0.442363, v_loss = 0.493820\n",
      "Ran epoch 130 and got t_acc = 0.814785 val_acc = 0.790000, t_loss = 0.440057, v_loss = 0.486005\n",
      "Ran epoch 131 and got t_acc = 0.812003 val_acc = 0.788000, t_loss = 0.440327, v_loss = 0.483928\n",
      "Ran epoch 132 and got t_acc = 0.818760 val_acc = 0.792000, t_loss = 0.439524, v_loss = 0.494140\n",
      "Ran epoch 133 and got t_acc = 0.813394 val_acc = 0.784000, t_loss = 0.438206, v_loss = 0.485048\n",
      "Ran epoch 134 and got t_acc = 0.820151 val_acc = 0.788000, t_loss = 0.432004, v_loss = 0.480767\n",
      "Ran epoch 135 and got t_acc = 0.819555 val_acc = 0.786000, t_loss = 0.431122, v_loss = 0.478332\n",
      "Ran epoch 136 and got t_acc = 0.815183 val_acc = 0.788000, t_loss = 0.433057, v_loss = 0.479567\n",
      "Ran epoch 137 and got t_acc = 0.817369 val_acc = 0.782000, t_loss = 0.432932, v_loss = 0.491143\n",
      "Ran epoch 138 and got t_acc = 0.815580 val_acc = 0.786000, t_loss = 0.429202, v_loss = 0.477869\n",
      "Ran epoch 139 and got t_acc = 0.816773 val_acc = 0.794000, t_loss = 0.424997, v_loss = 0.472551\n",
      "Ran epoch 140 and got t_acc = 0.822138 val_acc = 0.794000, t_loss = 0.422433, v_loss = 0.466702\n",
      "Ran epoch 141 and got t_acc = 0.823529 val_acc = 0.786000, t_loss = 0.420413, v_loss = 0.469433\n",
      "Ran epoch 142 and got t_acc = 0.823728 val_acc = 0.786000, t_loss = 0.418490, v_loss = 0.470972\n",
      "Ran epoch 143 and got t_acc = 0.826113 val_acc = 0.794000, t_loss = 0.415285, v_loss = 0.463420\n",
      "Ran epoch 144 and got t_acc = 0.820350 val_acc = 0.792000, t_loss = 0.418632, v_loss = 0.462428\n",
      "Ran epoch 145 and got t_acc = 0.818561 val_acc = 0.788000, t_loss = 0.422695, v_loss = 0.473551\n",
      "Ran epoch 146 and got t_acc = 0.817170 val_acc = 0.792000, t_loss = 0.422111, v_loss = 0.468234\n",
      "Ran epoch 147 and got t_acc = 0.825119 val_acc = 0.786000, t_loss = 0.410817, v_loss = 0.463354\n",
      "Ran epoch 148 and got t_acc = 0.826113 val_acc = 0.796000, t_loss = 0.406760, v_loss = 0.453052\n",
      "Ran epoch 149 and got t_acc = 0.821343 val_acc = 0.794000, t_loss = 0.411731, v_loss = 0.454064\n",
      "Ran epoch 150 and got t_acc = 0.828895 val_acc = 0.792000, t_loss = 0.410585, v_loss = 0.467551\n",
      "Ran epoch 151 and got t_acc = 0.826709 val_acc = 0.794000, t_loss = 0.409088, v_loss = 0.458674\n",
      "Ran epoch 152 and got t_acc = 0.830882 val_acc = 0.798000, t_loss = 0.401787, v_loss = 0.447049\n",
      "Ran epoch 153 and got t_acc = 0.830882 val_acc = 0.798000, t_loss = 0.399054, v_loss = 0.441120\n",
      "Ran epoch 154 and got t_acc = 0.828100 val_acc = 0.800000, t_loss = 0.402765, v_loss = 0.449524\n",
      "Ran epoch 155 and got t_acc = 0.832671 val_acc = 0.790000, t_loss = 0.400550, v_loss = 0.455234\n",
      "Ran epoch 156 and got t_acc = 0.834062 val_acc = 0.802000, t_loss = 0.395080, v_loss = 0.437779\n",
      "Ran epoch 157 and got t_acc = 0.839825 val_acc = 0.804000, t_loss = 0.391706, v_loss = 0.435646\n",
      "Ran epoch 158 and got t_acc = 0.841812 val_acc = 0.802000, t_loss = 0.390152, v_loss = 0.439616\n",
      "Ran epoch 159 and got t_acc = 0.832671 val_acc = 0.800000, t_loss = 0.392480, v_loss = 0.440302\n",
      "Ran epoch 160 and got t_acc = 0.838633 val_acc = 0.798000, t_loss = 0.386755, v_loss = 0.435624\n",
      "Ran epoch 161 and got t_acc = 0.841216 val_acc = 0.806000, t_loss = 0.387343, v_loss = 0.431629\n",
      "Ran epoch 162 and got t_acc = 0.839030 val_acc = 0.812000, t_loss = 0.389427, v_loss = 0.430217\n",
      "Ran epoch 163 and got t_acc = 0.843601 val_acc = 0.802000, t_loss = 0.386323, v_loss = 0.438971\n",
      "Ran epoch 164 and got t_acc = 0.847576 val_acc = 0.798000, t_loss = 0.379655, v_loss = 0.425474\n",
      "Ran epoch 165 and got t_acc = 0.849364 val_acc = 0.806000, t_loss = 0.378963, v_loss = 0.421822\n",
      "Ran epoch 166 and got t_acc = 0.849563 val_acc = 0.808000, t_loss = 0.380668, v_loss = 0.431452\n",
      "Ran epoch 167 and got t_acc = 0.843601 val_acc = 0.808000, t_loss = 0.384290, v_loss = 0.432207\n",
      "Ran epoch 168 and got t_acc = 0.852345 val_acc = 0.814000, t_loss = 0.374452, v_loss = 0.422041\n",
      "Ran epoch 169 and got t_acc = 0.853339 val_acc = 0.816000, t_loss = 0.373203, v_loss = 0.414426\n",
      "Ran epoch 170 and got t_acc = 0.844992 val_acc = 0.804000, t_loss = 0.375679, v_loss = 0.418216\n",
      "Ran epoch 171 and got t_acc = 0.853140 val_acc = 0.812000, t_loss = 0.372145, v_loss = 0.425328\n",
      "Ran epoch 172 and got t_acc = 0.855723 val_acc = 0.814000, t_loss = 0.365883, v_loss = 0.412580\n",
      "Ran epoch 173 and got t_acc = 0.843601 val_acc = 0.804000, t_loss = 0.373026, v_loss = 0.413884\n",
      "Ran epoch 174 and got t_acc = 0.854928 val_acc = 0.818000, t_loss = 0.371861, v_loss = 0.417402\n",
      "Ran epoch 175 and got t_acc = 0.851948 val_acc = 0.816000, t_loss = 0.365996, v_loss = 0.410062\n",
      "Ran epoch 176 and got t_acc = 0.855723 val_acc = 0.814000, t_loss = 0.363091, v_loss = 0.405019\n",
      "Ran epoch 177 and got t_acc = 0.859897 val_acc = 0.822000, t_loss = 0.365032, v_loss = 0.406945\n",
      "Ran epoch 178 and got t_acc = 0.852345 val_acc = 0.812000, t_loss = 0.360777, v_loss = 0.404387\n",
      "Ran epoch 179 and got t_acc = 0.853537 val_acc = 0.808000, t_loss = 0.357342, v_loss = 0.403776\n",
      "Ran epoch 180 and got t_acc = 0.859897 val_acc = 0.816000, t_loss = 0.360938, v_loss = 0.410958\n",
      "Ran epoch 181 and got t_acc = 0.856320 val_acc = 0.814000, t_loss = 0.356347, v_loss = 0.401485\n",
      "Ran epoch 182 and got t_acc = 0.859499 val_acc = 0.808000, t_loss = 0.352374, v_loss = 0.396052\n",
      "Ran epoch 183 and got t_acc = 0.859499 val_acc = 0.818000, t_loss = 0.363151, v_loss = 0.412203\n",
      "Ran epoch 184 and got t_acc = 0.858108 val_acc = 0.812000, t_loss = 0.354373, v_loss = 0.397581\n",
      "Ran epoch 185 and got t_acc = 0.865262 val_acc = 0.814000, t_loss = 0.346532, v_loss = 0.391319\n",
      "Ran epoch 186 and got t_acc = 0.868839 val_acc = 0.822000, t_loss = 0.350306, v_loss = 0.396812\n",
      "Ran epoch 187 and got t_acc = 0.858307 val_acc = 0.816000, t_loss = 0.351969, v_loss = 0.394102\n",
      "Ran epoch 188 and got t_acc = 0.867846 val_acc = 0.816000, t_loss = 0.341949, v_loss = 0.389273\n",
      "Ran epoch 189 and got t_acc = 0.866653 val_acc = 0.818000, t_loss = 0.347133, v_loss = 0.397326\n",
      "Ran epoch 190 and got t_acc = 0.862878 val_acc = 0.820000, t_loss = 0.347769, v_loss = 0.387097\n",
      "Ran epoch 191 and got t_acc = 0.874603 val_acc = 0.830000, t_loss = 0.336437, v_loss = 0.380465\n",
      "Ran epoch 192 and got t_acc = 0.871622 val_acc = 0.822000, t_loss = 0.337510, v_loss = 0.387916\n",
      "Ran epoch 193 and got t_acc = 0.866653 val_acc = 0.818000, t_loss = 0.339164, v_loss = 0.379050\n",
      "Ran epoch 194 and got t_acc = 0.876391 val_acc = 0.828000, t_loss = 0.332853, v_loss = 0.372616\n",
      "Ran epoch 195 and got t_acc = 0.874205 val_acc = 0.824000, t_loss = 0.332019, v_loss = 0.375745\n",
      "Ran epoch 196 and got t_acc = 0.873609 val_acc = 0.820000, t_loss = 0.330548, v_loss = 0.374932\n",
      "Ran epoch 197 and got t_acc = 0.875199 val_acc = 0.830000, t_loss = 0.328082, v_loss = 0.371608\n",
      "Ran epoch 198 and got t_acc = 0.879571 val_acc = 0.828000, t_loss = 0.327037, v_loss = 0.369555\n",
      "Ran epoch 199 and got t_acc = 0.879173 val_acc = 0.832000, t_loss = 0.324387, v_loss = 0.369262\n",
      "For Q4:\n",
      "Best train accuracy: 0.879570747217806\n",
      "Best val accuracy: 0.832\n"
     ]
    }
   ],
   "source": [
    "lr=0.0007\n",
    "\n",
    "train_log = []\n",
    "val_log = []\n",
    "losses = []\n",
    "train_count = []\n",
    "counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "CNN = []\n",
    "\n",
    "CNN.append(conv_layer(8, (3,3,3), lr))\n",
    "CNN.append(ReLU())\n",
    "CNN.append(pool_layer((2,2)))\n",
    "\n",
    "CNN.append(conv_layer(16, (3,3,8) , lr))\n",
    "CNN.append(ReLU())\n",
    "CNN.append(pool_layer((2,2)))\n",
    "\n",
    "\n",
    "CNN.append(conv_layer(32, (3,3,16), lr))\n",
    "CNN.append(ReLU())\n",
    "CNN.append(pool_layer((2,2)))\n",
    "\n",
    "\n",
    "CNN.append(reshape_layer())\n",
    "\n",
    "\n",
    "CNN.append(weights_layer(128,100,lr))\n",
    "CNN.append(ReLU())\n",
    "CNN.append(dropout_layer(0.5))\n",
    "CNN.append(weights_layer(100,100,lr))\n",
    "CNN.append(ReLU())\n",
    "CNN.append(dropout_layer(0.5))\n",
    "CNN.append(weights_layer(100,5,lr))\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    #for x_batch,y_batch in iterate_minibatches(X_TRAIN,Y_TRAIN,batchsize=534,shuffle=True):\n",
    "    #  train(CNN,x_batch,y_batch, 1)\n",
    "\n",
    "    train(CNN,X_TRAIN,Y_TRAIN,1)\n",
    "\n",
    "    train_predictions, train_loss = predict(CNN,X_TRAIN, Y_TRAIN, 0)\n",
    "\n",
    "    val_predictions, val_loss = predict(CNN,X_VAL, Y_VAL, 0)\n",
    "\n",
    "    train_log.append(np.mean(train_predictions==Y_TRAIN))\n",
    "\n",
    "    val_log.append(np.mean(val_predictions==Y_VAL))\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(\"Ran epoch %d and got t_acc = %f val_acc = %f, t_loss = %f, v_loss = %f\" % (epoch, train_log[-1], val_log[-1], train_losses[-1], val_losses[-1]))\n",
    "\n",
    "\n",
    "\n",
    "print(\"For Q4:\")\n",
    "print(\"Best train accuracy:\",max(train_log))\n",
    "print(\"Best val accuracy:\",max(val_log))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:24:31.835141Z",
     "iopub.status.busy": "2024-03-03T17:24:31.834467Z",
     "iopub.status.idle": "2024-03-03T17:24:35.039996Z",
     "shell.execute_reply": "2024-03-03T17:24:35.039090Z",
     "shell.execute_reply.started": "2024-03-03T17:24:31.835114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Q5:\n",
      "For Category  Bacterialblight  , Got Accuracy 0.84\n",
      "For Category  Blast  , Got Accuracy 0.71\n",
      "For Category  Brownspot  , Got Accuracy 0.95\n",
      "For Category  Tungro  , Got Accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "num_partition = 4\n",
    "x_test_arrays = np.split(X_TEST, num_partition)\n",
    "y_test_arrays = np.split(np.array(Y_TEST), num_partition)\n",
    "n_images = len (x_test_arrays[0])\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "print ('For Q5:')\n",
    "for i in range(num_partition):\n",
    "    class_predictions, class_loss = predict(CNN,x_test_arrays[i], y_test_arrays[i], 0)\n",
    "    accuracy = np.mean(class_predictions==y_test_arrays[i])\n",
    "    print('For Category ' , CATEGORIES[i],' , Got Accuracy' , accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "y_pos = np.arange(len(CATEGORIES))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:24:35.041924Z",
     "iopub.status.busy": "2024-03-03T17:24:35.041268Z",
     "iopub.status.idle": "2024-03-03T17:24:35.330535Z",
     "shell.execute_reply": "2024-03-03T17:24:35.329531Z",
     "shell.execute_reply.started": "2024-03-03T17:24:35.041889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "َََQ6: ACCR = 0.870000\n"
     ]
    }
   ],
   "source": [
    "predicted_test, test_loss = predict(CNN,X_TEST, Y_TEST, 0)\n",
    "accuracy = np.mean(predicted_test==np.array(Y_TEST))\n",
    "    \n",
    "print(\"َََQ6: ACCR = %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:31:29.887351Z",
     "iopub.status.busy": "2024-03-03T17:31:29.886388Z",
     "iopub.status.idle": "2024-03-03T17:31:29.894038Z",
     "shell.execute_reply": "2024-03-03T17:31:29.892965Z",
     "shell.execute_reply.started": "2024-03-03T17:31:29.887316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer-wise summary:\n",
      "Layer 0: conv_layer - Parameters: 0\n",
      "Layer 1: ReLU - Parameters: 0\n",
      "Layer 2: pool_layer - Parameters: 0\n",
      "Layer 3: conv_layer - Parameters: 0\n",
      "Layer 4: ReLU - Parameters: 0\n",
      "Layer 5: pool_layer - Parameters: 0\n",
      "Layer 6: conv_layer - Parameters: 0\n",
      "Layer 7: ReLU - Parameters: 0\n",
      "Layer 8: pool_layer - Parameters: 0\n",
      "Layer 9: reshape_layer - Parameters: 0\n",
      "Layer 10: weights_layer - Parameters: 0\n",
      "Layer 11: ReLU - Parameters: 0\n",
      "Layer 12: dropout_layer - Parameters: 0\n",
      "Layer 13: weights_layer - Parameters: 0\n",
      "Layer 14: ReLU - Parameters: 0\n",
      "Layer 15: dropout_layer - Parameters: 0\n",
      "Layer 16: weights_layer - Parameters: 0\n",
      "\n",
      "Total trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "def summary(CNN):\n",
    "    total_params = 0\n",
    "    print(\"Layer-wise summary:\")\n",
    "    for i, layer in enumerate(CNN):\n",
    "        layer_name = layer.__class__.__name__\n",
    "        params = layer.params if hasattr(layer, 'params') else 0\n",
    "        total_params += params\n",
    "        print(f\"Layer {i}: {layer_name} - Parameters: {params}\")\n",
    "\n",
    "    print(\"\\nTotal trainable parameters:\", total_params)\n",
    "summary(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T17:33:21.434186Z",
     "iopub.status.busy": "2024-03-03T17:33:21.433744Z",
     "iopub.status.idle": "2024-03-03T17:33:21.447031Z",
     "shell.execute_reply": "2024-03-03T17:33:21.445850Z",
     "shell.execute_reply.started": "2024-03-03T17:33:21.434154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer-wise summary:\n",
      "Layer 0: conv_layer - Parameters: 216\n",
      "Layer 1: ReLU - Parameters: 0\n",
      "Layer 2: pool_layer - Parameters: 0\n",
      "Layer 3: conv_layer - Parameters: 1152\n",
      "Layer 4: ReLU - Parameters: 0\n",
      "Layer 5: pool_layer - Parameters: 0\n",
      "Layer 6: conv_layer - Parameters: 4608\n",
      "Layer 7: ReLU - Parameters: 0\n",
      "Layer 8: pool_layer - Parameters: 0\n",
      "Layer 9: reshape_layer - Parameters: 0\n",
      "Layer 10: weights_layer - Parameters: 12800\n",
      "Layer 11: ReLU - Parameters: 0\n",
      "Layer 12: dropout_layer - Parameters: 0\n",
      "Layer 13: weights_layer - Parameters: 10000\n",
      "Layer 14: ReLU - Parameters: 0\n",
      "Layer 15: dropout_layer - Parameters: 0\n",
      "Layer 16: weights_layer - Parameters: 500\n",
      "\n",
      "Total trainable parameters: 29276\n"
     ]
    }
   ],
   "source": [
    "def summary(CNN):\n",
    "    total_params = 0\n",
    "    print(\"Layer-wise summary:\")\n",
    "    for i, layer in enumerate(CNN):\n",
    "        layer_name = layer.__class__.__name__\n",
    "        params = getattr(layer, 'params', 0)\n",
    "        total_params += params\n",
    "        print(f\"Layer {i}: {layer_name} - Parameters: {params}\")\n",
    "\n",
    "    print(\"\\nTotal trainable parameters:\", total_params)\n",
    "\n",
    "\n",
    "CNN = []\n",
    "\n",
    "CNN.append(conv_layer(8, (3,3,3), lr))\n",
    "CNN.append(ReLU())\n",
    "CNN.append(pool_layer((2,2)))\n",
    "\n",
    "CNN.append(conv_layer(16, (3,3,8) , lr))\n",
    "CNN.append(ReLU())\n",
    "CNN.append(pool_layer((2,2)))\n",
    "\n",
    "\n",
    "CNN.append(conv_layer(32, (3,3,16), lr))\n",
    "CNN.append(ReLU())\n",
    "CNN.append(pool_layer((2,2)))\n",
    "\n",
    "\n",
    "CNN.append(reshape_layer())\n",
    "\n",
    "\n",
    "CNN.append(weights_layer(128,100,lr))\n",
    "CNN.append(ReLU())\n",
    "CNN.append(dropout_layer(0.5))\n",
    "CNN.append(weights_layer(100,100,lr))\n",
    "CNN.append(ReLU())\n",
    "CNN.append(dropout_layer(0.5))\n",
    "CNN.append(weights_layer(100,5,lr))\n",
    "\n",
    "\n",
    "summary(CNN)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4245440,
     "sourceId": 7316033,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4528102,
     "sourceId": 7746000,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4529634,
     "sourceId": 7748259,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30666,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
